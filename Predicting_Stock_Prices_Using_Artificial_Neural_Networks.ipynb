{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p9QWSGtiHgM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "how to implement the stock prediction model using neural networks step by step practically. We will start with a detailed explanation of neural networks, including the essential components (layers, activations, feedforward, and backpropagation) and transition to deep learning. We then move on to implementations from scratch with scikit-learn and TensorFlow. The ways to avoid overfitting, such as dropout and early stopping. Finally, you will apply what we covered previously to solve our stock price prediction problem."
      ],
      "metadata": {
        "id": "0_ycQcGgoEmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBXHZAOmiS3T"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0/(1+ np.exp(-z))\n",
        "def sigmoid_derivative(z):\n",
        "    return sigmoid(z) * (1.0-sigmoid(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xD-Qd-pgiVB1"
      },
      "outputs": [],
      "source": [
        "def train(X, y, n_hidden, learning_rate, n_iter):\n",
        "    m, n_input = X.shape\n",
        "    W1=np.random.randn(n_input, n_hidden)\n",
        "    b1=np.zeros((1, n_hidden))\n",
        "    W2=np.random.randn(n_hidden, 1)\n",
        "    b2=np.zeros((1,1))\n",
        "    for i in range(1, n_iter+1):\n",
        "        Z2=np.matmul(X,W1) + b1\n",
        "        A2=sigmoid(Z2)\n",
        "        Z3=np.matmul(A2, W2) + b2\n",
        "        A3=Z3\n",
        "        dZ3=A3-y\n",
        "        dW2=np.matmul(A2.T, dZ3)\n",
        "        db2=np.sum(dZ3, axis=0, keepdims=True)\n",
        "        dZ2=np.matmul(dZ3, W2.T) * sigmoid_derivative(Z2)\n",
        "        dW1=np.matmul(X.T, dZ2)\n",
        "        db1=np.sum(dZ2, axis=0)\n",
        "        W2=W2-learning_rate*dW2/m\n",
        "        b2=b2-learning_rate*db2/m\n",
        "        W1=W1-learning_rate*dW1/m\n",
        "\n",
        "        b1=b1-learning_rate*db1/m\n",
        "        if i % 100==0:\n",
        "            cost=np.mean((y-A3)**2)\n",
        "            print('Iteration %i, training loss: %f' % (i,cost))\n",
        "    model={'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2}\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik2Txac3iWp9"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "boston = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([boston.values[::2, :], boston.values[1::2, :2]])\n",
        "target = boston.values[1::2, 2]\n",
        "#boston=datasets.load_boston()\n",
        "num_test=10 #the last 10 samples as testing set\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X_train=data[:-num_test, :]\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "y_train=target[:-num_test].reshape(-1,1)\n",
        "X_test=data[-num_test:, :]\n",
        "X_test=scaler.transform(X_test)\n",
        "y_test=target[-num_test:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oImuZ1YiiY6t",
        "outputId": "d2416fd3-b421-4a73-d58c-defd6cb6f6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100, training loss: 12.300093\n",
            "Iteration 200, training loss: 8.685077\n",
            "Iteration 300, training loss: 7.463284\n",
            "Iteration 400, training loss: 6.771094\n",
            "Iteration 500, training loss: 6.211099\n",
            "Iteration 600, training loss: 5.776562\n",
            "Iteration 700, training loss: 5.398643\n",
            "Iteration 800, training loss: 5.109906\n",
            "Iteration 900, training loss: 4.859596\n",
            "Iteration 1000, training loss: 4.630014\n",
            "Iteration 1100, training loss: 4.418704\n",
            "Iteration 1200, training loss: 4.231236\n",
            "Iteration 1300, training loss: 4.067245\n",
            "Iteration 1400, training loss: 3.921186\n",
            "Iteration 1500, training loss: 3.787546\n",
            "Iteration 1600, training loss: 3.662822\n",
            "Iteration 1700, training loss: 3.546226\n",
            "Iteration 1800, training loss: 3.436772\n",
            "Iteration 1900, training loss: 3.328227\n",
            "Iteration 2000, training loss: 3.230002\n"
          ]
        }
      ],
      "source": [
        "n_hidden=20\n",
        "learning_rate=0.1\n",
        "n_iter=2000\n",
        "model=train(X_train,y_train,n_hidden,learning_rate,n_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5coSTR8jktM"
      },
      "outputs": [],
      "source": [
        "def predict(x, model):\n",
        "    W1=model['W1']\n",
        "    b1=model['b1']\n",
        "    W2=model['W2']\n",
        "    b2=model['b2']\n",
        "    A2=sigmoid(np.matmul(x,W1)+b1)\n",
        "    A3=np.matmul(A2, W2)+b2\n",
        "    return A3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsxhlqNdjpwu"
      },
      "outputs": [],
      "source": [
        "predictions=predict(X_test, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-y5MKzhjr1V",
        "outputId": "160b70d2-c37e-4baf-86a4-3e72105ebbdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17.92227214]\n",
            " [18.84809464]\n",
            " [20.53148989]\n",
            " [18.43197427]\n",
            " [19.7850541 ]\n",
            " [22.35583015]\n",
            " [20.72281855]\n",
            " [28.41174004]\n",
            " [25.96755263]\n",
            " [20.7422927 ]]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRgscedbjtmz",
        "outputId": "a6aea926-8e9d-4a16-afb5-08425a38df69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]\n"
          ]
        }
      ],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV-R7m9AkWAb"
      },
      "source": [
        "### 2. scikit-learn Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD8lu8i6jvko"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "nn_scikit=MLPRegressor(hidden_layer_sizes=(16,8), activation='relu', solver='adam',\n",
        "                       learning_rate_init=0.001, random_state=42, max_iter=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncjLWhHRkPPy",
        "outputId": "a7efc838-1376-419f-d105-b3f4e0962d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16.79582331 18.55538023 21.07961496 19.21362606 18.50955771 23.5608387\n",
            " 22.27916529 27.11909153 24.70251262 22.05522035]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "nn_scikit.fit(X_train, y_train)\n",
        "predictions =nn_scikit.predict(X_test)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtORf2nkkSY",
        "outputId": "76839326-ef1b-4604-aa12-cb30992a9117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.933482332708795\n"
          ]
        }
      ],
      "source": [
        "print(np.mean((y_test-predictions)**2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb5ec6wgkpt4"
      },
      "source": [
        "Tensor Flow Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2_4oonTknAg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpY_c8nSkx3Y"
      },
      "outputs": [],
      "source": [
        "model=keras.Sequential([keras.layers.Dense(units=20, activation='relu'), keras.layers.Dense(units=8, activation='relu'),keras.layers.Dense(units=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-q6SpjAk1f9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.02))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqKB4diTk6Q4",
        "outputId": "f28b33fe-89f2-4351-9423-7be643307eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 1s 1ms/step - loss: 433.3733\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 80.1758\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 28.8860\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 22.7008\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 18.7512\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 16.3690\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 14.0681\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 14.5999\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 12.4302\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.4262\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.0961\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.1060\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.6665\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.2235\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.9467\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.1561\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.2821\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.9229\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.8228\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.8659\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.5246\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.8616\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.1393\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.9391\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 7.9971\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.7637\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.9892\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.5311\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.8118\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.4395\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.8580\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.1321\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.7158\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.7556\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.5731\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 6.8773\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 6.9334\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 6.2283\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.5765\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 6.6276\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.5334\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.2490\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.5838\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.2180\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.1378\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.1373\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.1230\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.0474\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.3881\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.4414\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.9159\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.5525\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.4728\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.4112\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.4641\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.6600\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.8171\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.4161\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.1079\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.3685\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.3722\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.9887\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.3579\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.5224\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.2096\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.4813\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.6326\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.1111\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.3684\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.4275\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.9181\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.7270\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.9343\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.0131\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.6924\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.8228\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.9135\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.6331\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.4780\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.0096\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.5402\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.7356\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.7436\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.1260\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.5270\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.7525\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.1686\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.3657\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.3919\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.3907\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.4524\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.7578\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.9634\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.2461\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.5864\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.9711\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.5972\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.9846\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.4221\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.3883\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.8759\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.1233\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.1028\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.3749\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.4807\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.1768\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.9177\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.8528\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.0452\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.0196\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8359\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.7295\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.9689\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8447\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8449\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.1754\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.1890\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 5.3173\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.6101\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.9763\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5761\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8402\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.0526\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.6384\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4286\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5848\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.0457\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.9670\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.9067\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.1264\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8404\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.9839\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.9115\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5682\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.9930\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.2894\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8876\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5754\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5805\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3761\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.9020\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4121\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3747\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1276\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.6971\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.7087\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5081\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.7533\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.7193\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.6007\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3384\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3860\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5601\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4823\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 4.0343\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1828\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1617\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2253\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2997\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.6879\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1835\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3558\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1204\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9544\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1851\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.6866\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3351\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2135\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.2844\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4499\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8739\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9477\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5255\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3049\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3094\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.6443\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4661\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9438\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1354\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.3045\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.7041\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4733\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.8584\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.7963\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.5076\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3580\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.8793\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7605\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9527\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1342\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3312\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2120\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4273\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.2051\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3937\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3205\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2351\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.0589\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3224\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.9468\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2877\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.1135\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8393\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9825\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.0836\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1606\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8450\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8374\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8435\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.0560\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9702\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8811\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8976\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4728\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3717\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1290\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9495\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8566\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8453\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6874\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6667\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.0235\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1464\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1565\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.0393\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.8254\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6052\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7663\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8353\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6820\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.7170\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7179\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6235\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6185\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9530\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8051\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2385\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1044\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9512\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6817\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6724\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9826\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.4449\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9141\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6957\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8014\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.2506\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7890\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6629\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7949\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9221\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7555\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.5354\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6056\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4608\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4910\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7589\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.5196\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7316\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6702\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.5881\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8388\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.5099\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8367\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8220\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7434\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6971\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6149\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.8465\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7421\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6629\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1723\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7696\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.9397\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1994\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.3763\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6143\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6603\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4156\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.8078\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6154\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.5925\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7016\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7026\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6784\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7088\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.5875\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 3.1529\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.6344\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4987\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.8834\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.5632\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4737\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.3870\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4291\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.3890\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4637\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.4834\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.4312\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11461affa0>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "model.fit(X_train,y_train, epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrnxnppkk8FE",
        "outputId": "6bac9ce1-49ba-4174-acae-840b28f81a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n",
            "[14.374293 20.34782  22.487867 19.427124 19.157806 26.405304 21.395239\n",
            " 30.346127 27.383427 19.784338]\n"
          ]
        }
      ],
      "source": [
        "predictions_2=model.predict(X_test)[:,0]\n",
        "print(predictions_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDOtccPIlLM3",
        "outputId": "60b4c079-77a8-497d-c6f5-0d972aaedaaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.28598603534936\n"
          ]
        }
      ],
      "source": [
        "print(np.mean((y_test-predictions_2)**2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_EeBSQIlRr_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw9jHqLZlly-"
      },
      "source": [
        "Handling Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxfIgqt5lNKl"
      },
      "outputs": [],
      "source": [
        "model=keras.Sequential([keras.layers.Dense(units=32, activation='relu'), tf.keras.layers.Dropout(0.5),keras.layers.Dense(units=1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxWNrd2Dltw4"
      },
      "source": [
        "Stock Prices Prediction using Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "tc9TAuVvlw09",
        "outputId": "3c145a53-b32c-47b3-e04a-ee2c47a0fc6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Open     High      Low    Close     Volume\n",
              "Date                                                     \n",
              "2005-12-01  10806.0  10934.9  10806.0  10912.6  256932865\n",
              "2005-12-02  10912.0  10921.4  10861.7  10877.5  214888854\n",
              "2005-12-05  10877.0  10877.0  10810.7  10835.0  237430947\n",
              "2005-12-06  10835.4  10936.2  10835.4  10856.9  264721465\n",
              "2005-12-07  10856.9  10868.1  10764.0  10810.9  243543206\n",
              "2005-12-08  10808.4  10847.2  10729.7  10755.1  253313750\n",
              "2005-12-09  10751.8  10806.0  10729.9  10778.6  238907145"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ce741d7-0a79-416d-ac9d-f05b0dfa26c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2005-12-01</th>\n",
              "      <td>10806.0</td>\n",
              "      <td>10934.9</td>\n",
              "      <td>10806.0</td>\n",
              "      <td>10912.6</td>\n",
              "      <td>256932865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-02</th>\n",
              "      <td>10912.0</td>\n",
              "      <td>10921.4</td>\n",
              "      <td>10861.7</td>\n",
              "      <td>10877.5</td>\n",
              "      <td>214888854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-05</th>\n",
              "      <td>10877.0</td>\n",
              "      <td>10877.0</td>\n",
              "      <td>10810.7</td>\n",
              "      <td>10835.0</td>\n",
              "      <td>237430947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-06</th>\n",
              "      <td>10835.4</td>\n",
              "      <td>10936.2</td>\n",
              "      <td>10835.4</td>\n",
              "      <td>10856.9</td>\n",
              "      <td>264721465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-07</th>\n",
              "      <td>10856.9</td>\n",
              "      <td>10868.1</td>\n",
              "      <td>10764.0</td>\n",
              "      <td>10810.9</td>\n",
              "      <td>243543206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-08</th>\n",
              "      <td>10808.4</td>\n",
              "      <td>10847.2</td>\n",
              "      <td>10729.7</td>\n",
              "      <td>10755.1</td>\n",
              "      <td>253313750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-09</th>\n",
              "      <td>10751.8</td>\n",
              "      <td>10806.0</td>\n",
              "      <td>10729.9</td>\n",
              "      <td>10778.6</td>\n",
              "      <td>238907145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce741d7-0a79-416d-ac9d-f05b0dfa26c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ce741d7-0a79-416d-ac9d-f05b0dfa26c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ce741d7-0a79-416d-ac9d-f05b0dfa26c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "mydata=pd.read_csv(r\"20051201_20051210.csv\",index_col='Date')\n",
        "mydata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqJEBd-sosNZ"
      },
      "outputs": [],
      "source": [
        "#implement feature generation by starting with a sub-function that directly creates features from the original six features\n",
        "def add_original_feature(df, df_new):\n",
        "    df_new['open'] = df['Open']\n",
        "    df_new['open_1'] = df['Open'].shift(1)\n",
        "    df_new['close_1'] = df['Close'].shift(1)\n",
        "    df_new['high_1'] = df['High'].shift(1)\n",
        "    df_new['low_1'] = df['Low'].shift(1)\n",
        "    df_new['volume_1'] = df['Volume'].shift(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hjseo3XnaBY"
      },
      "outputs": [],
      "source": [
        "#develop a sub-function that generates six features related to average close prices\n",
        "def add_avg_price(df, df_new):\n",
        "    df_new['avg_price_5']=df['Close'].rolling(5).mean().shift(1)\n",
        "    df_new['avg_price_30']=df['Close'].rolling(21).mean().shift(1)\n",
        "    df_new['avg_price_365']=df['Close'].rolling(252).mean().shift(1)\n",
        "    df_new['ratio_avg_price_5_30']=df_new['avg_price_5']/df_new['avg_price_30']\n",
        "    df_new['ratio_avg_price_5_365']=df_new['avg_price_5']/df_new['avg_price_365']\n",
        "    df_new['ratio_avg_price_30_365']=df_new['avg_price_30']/df_new['avg_price_365']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RMhKnJInrj7"
      },
      "outputs": [],
      "source": [
        "#a sub-function that generates six features related to average volumes is as follows\n",
        "def add_avg_volume(df, df_new):\n",
        "    df_new['avg_volume_5'] = df['Volume'].rolling(5).mean().shift(1)\n",
        "    df_new['avg_volume_30'] =df['Volume'].rolling(21).mean().shift(1)\n",
        "    df_new['avg_volume_365'] =df['Volume'].rolling(252).mean().shift(1)\n",
        "    df_new['ratio_avg_volume_5_30']=df_new['avg_volume_5']/df_new['avg_volume_30']\n",
        "    df_new['ratio_avg_volume_5_365']=df_new['avg_volume_5']/df_new['avg_volume_365']\n",
        "    df_new['ratio_avg_volume_30_365']=df_new['avg_volume_30']/df_new['avg_volume_365']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te5PvDfLntRU"
      },
      "outputs": [],
      "source": [
        "#for the standard deviation, we develop the following sub-function for the price related features\n",
        "def add_std_price(df, df_new):\n",
        "    df_new['std_price_5'] =df['Close'].rolling(5).std().shift(1)\n",
        "    df_new['std_price_30'] =df['Close'].rolling(21).std().shift(1)\n",
        "    df_new['std_price_365'] =df['Close'].rolling(252).std().shift(1)\n",
        "    df_new['ratio_std_price_5_30'] =df_new['std_price_5']/df_new['std_price_30']\n",
        "    df_new['ratio_std_price_5_365']=df_new['std_price_5']/df_new['std_price_365']\n",
        "    df_new['ratio_std_price_30_365']=df_new['std_price_30']/df_new['std_price_365']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcth9wK7nvIw"
      },
      "outputs": [],
      "source": [
        "#Similarly, a sub-function that generates six volume-based standard deviation features is as follows.\n",
        "def add_std_volume(df, df_new):\n",
        "    df_new['std_volume_5']=df['Volume'].rolling(5).std().shift(1)\n",
        "    df_new['std_volume_30']=df['Volume'].rolling(21).std().shift(1)\n",
        "    df_new['std_volume_365'] =df['Volume'].rolling(252).std().shift (1)\n",
        "    df_new['ratio_std_volume_5_30']=df_new['std_volume_5']/df_new['std_volume_30']\n",
        "    df_new['ratio_std_volume_5_365'] =df_new['std_volume_5']/df_new['std_volume_365']\n",
        "    df_new['ratio_std_volume_30_365'] =df_new['std_volume_30']/df_new['std_volume_365']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSavEik4nwzG"
      },
      "outputs": [],
      "source": [
        "#Seven return-based features are generated using the following sub-function.\n",
        "def add_return_feature(df, df_new):\n",
        "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1))/df['Close'].shift(1)).shift(1)\n",
        "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5))/df['Close'].shift(5)).shift(1)\n",
        "    df_new['return_30'] = ((df['Close'] -df['Close'].shift(21))/df['Close'].shift (21)).shift(1)\n",
        "    df_new['return_365'] = ((df['Close'] -df['Close'].shift(252))/df['Close'].shift (252)).shift(1)\n",
        "    df_new['moving_avg_5'] =df_new['return_1'].rolling(5).mean().shift(1)\n",
        "    df_new['moving_avg_30'] =df_new['return_1'].rolling(21).mean().shift(1)\n",
        "    df_new['moving_avg_365'] =df_new['return_1'].rolling(252).mean().shift(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmJi2WhgnykG"
      },
      "outputs": [],
      "source": [
        "#Finally, we put together the main feature generation function that calls all the preceding sub-functions.\n",
        "def generate_features(df):\n",
        "\n",
        "    df_new=pd.DataFrame()\n",
        "    # 6 original features\n",
        "    add_original_feature(df, df_new)\n",
        "    # 31 generated features\n",
        "    add_avg_price(df,df_new)\n",
        "    add_avg_volume(df, df_new)\n",
        "    add_std_price(df, df_new)\n",
        "    add_std_volume(df,df_new)\n",
        "    add_return_feature(df,df_new)\n",
        "    #the target\n",
        "    df_new['close']=df['Close']\n",
        "    df_new=df_new.dropna(axis=0)\n",
        "    return df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po-VIpk3n0bP"
      },
      "outputs": [],
      "source": [
        "data_raw=pd.read_csv(r\"19880101_20191231.csv\", index_col='Date')\n",
        "data=generate_features(data_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMmVOlvqn2ej",
        "outputId": "68aebb3f-7cf8-45eb-c3e8-99cc6625768c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              open  open_1  close_1  high_1   low_1    volume_1  avg_price_5  \\\n",
            "Date                                                                           \n",
            "1989-01-04  2146.6  2168.4   2144.6  2168.4  2127.1  17302883.0      2165.00   \n",
            "1989-01-05  2177.7  2146.6   2177.7  2183.4  2146.6  15714720.0      2168.00   \n",
            "1989-01-06  2190.5  2177.7   2190.5  2205.2  2173.0  20303094.0      2172.82   \n",
            "1989-01-09  2194.3  2190.5   2194.3  2213.8  2182.3  16494441.0      2175.14   \n",
            "1989-01-10  2199.5  2194.3   2199.5  2209.1  2185.0  18410324.0      2181.32   \n",
            "\n",
            "            avg_price_30  avg_price_365  ratio_avg_price_5_30  ...  \\\n",
            "Date                                                           ...   \n",
            "1989-01-04      2150.624       2062.113                 1.007  ...   \n",
            "1989-01-05      2154.690       2062.668                 1.006  ...   \n",
            "1989-01-06      2157.867       2063.218                 1.007  ...   \n",
            "1989-01-09      2160.005       2064.341                 1.007  ...   \n",
            "1989-01-10      2162.190       2065.351                 1.009  ...   \n",
            "\n",
            "            ratio_std_volume_5_365  ratio_std_volume_30_365  return_1  \\\n",
            "Date                                                                    \n",
            "1989-01-04                   0.563                    0.723    -0.011   \n",
            "1989-01-05                   0.474                    0.724     0.015   \n",
            "1989-01-06                   0.580                    0.748     0.006   \n",
            "1989-01-09                   0.516                    0.746     0.002   \n",
            "1989-01-10                   0.279                    0.742     0.002   \n",
            "\n",
            "            return_5  return_30  return_365  moving_avg_5  moving_avg_30  \\\n",
            "Date                                                                       \n",
            "1989-01-04    -0.011      0.020       0.056         0.001          0.001   \n",
            "1989-01-05     0.007      0.041       0.069        -0.002          0.001   \n",
            "1989-01-06     0.011      0.031       0.068         0.001          0.002   \n",
            "1989-01-09     0.005      0.021       0.148         0.002          0.001   \n",
            "1989-01-10     0.014      0.021       0.131         0.001          0.001   \n",
            "\n",
            "            moving_avg_365   close  \n",
            "Date                                \n",
            "1989-01-04           0.000  2177.7  \n",
            "1989-01-05           0.000  2190.5  \n",
            "1989-01-06           0.000  2194.3  \n",
            "1989-01-09           0.000  2199.5  \n",
            "1989-01-10           0.001  2193.2  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ],
      "source": [
        "print(data.round(decimals=3).head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpaoxX7po9vp"
      },
      "outputs": [],
      "source": [
        "#Training a simple neural network.\n",
        "#We load the stock data, generate features, and label the generate_features function, Predicting Stock Prices with Regression Algorithms:\n",
        "data_raw=pd.read_csv(r\"19880101_20191231.csv\", index_col='Date')\n",
        "data=generate_features(data_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxcQUnAypLQi"
      },
      "outputs": [],
      "source": [
        "#We construct the training set using data from 1988 to 2018 and the testing set using data from 2019:\n",
        "start_train='1988-01-01'\n",
        "end_train='2018-12-31'\n",
        "start_test='2019-01-01'\n",
        "end_test='2019-12-31'\n",
        "data_train=data.loc[start_train:end_train]\n",
        "X_train=data_train.drop('close', axis=1).values\n",
        "y_train=data_train['close'].values\n",
        "data_test=data.loc[start_test:end_test]\n",
        "X_test=data_test.drop('close',axis=1).values\n",
        "y_test=data_test['close'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8AKwijupN9Z"
      },
      "outputs": [],
      "source": [
        "#We need to normalize features into the same or a comparable scale. We do so by removing the mean and rescaling to unit variance:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhxv0fhVpP0n"
      },
      "outputs": [],
      "source": [
        "#We rescale both sets with the scaler taught by the training set:\n",
        "X_scaled_train=scaler.fit_transform(X_train)\n",
        "X_scaled_test=scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49La1vDTpRgl"
      },
      "outputs": [],
      "source": [
        "#We now build a neural network model using the Keras Sequential API:\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model=Sequential([Dense(units=32, activation='relu'), Dense(units=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FResdRDbpneT"
      },
      "outputs": [],
      "source": [
        "#And we compile the model by using Adam as the optimizer with a learning rate of 0.1 and MSE as the learning goal:\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFTZtrjBpudp",
        "outputId": "e9eef121-ad45-4513-8e23-fbd460c001a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "237/237 [==============================] - 1s 1ms/step - loss: 33025302.0000\n",
            "Epoch 2/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 2049651.7500\n",
            "Epoch 3/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 514644.3125\n",
            "Epoch 4/100\n",
            "237/237 [==============================] - 0s 987us/step - loss: 179688.3438\n",
            "Epoch 5/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 86373.3047\n",
            "Epoch 6/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 50651.1016\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - 0s 968us/step - loss: 35019.1992\n",
            "Epoch 8/100\n",
            "237/237 [==============================] - 0s 992us/step - loss: 28108.4336\n",
            "Epoch 9/100\n",
            "237/237 [==============================] - 0s 990us/step - loss: 26475.5352\n",
            "Epoch 10/100\n",
            "237/237 [==============================] - 0s 986us/step - loss: 25541.5371\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - 0s 913us/step - loss: 29194.7422\n",
            "Epoch 12/100\n",
            "237/237 [==============================] - 0s 974us/step - loss: 22834.3887\n",
            "Epoch 13/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 23015.8242\n",
            "Epoch 14/100\n",
            "237/237 [==============================] - 0s 966us/step - loss: 28389.7266\n",
            "Epoch 15/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 31328.6582\n",
            "Epoch 16/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 27117.4766\n",
            "Epoch 17/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 29833.5645\n",
            "Epoch 18/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 29513.3164\n",
            "Epoch 19/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 31132.4355\n",
            "Epoch 20/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 27296.4277\n",
            "Epoch 21/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 28448.1152\n",
            "Epoch 22/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 31500.4102\n",
            "Epoch 23/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 31660.4160\n",
            "Epoch 24/100\n",
            "237/237 [==============================] - 0s 951us/step - loss: 25664.4746\n",
            "Epoch 25/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 27908.2871\n",
            "Epoch 26/100\n",
            "237/237 [==============================] - 0s 980us/step - loss: 30241.4902\n",
            "Epoch 27/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 27360.7148\n",
            "Epoch 28/100\n",
            "237/237 [==============================] - 0s 946us/step - loss: 29034.5254\n",
            "Epoch 29/100\n",
            "237/237 [==============================] - 0s 984us/step - loss: 27310.1641\n",
            "Epoch 30/100\n",
            "237/237 [==============================] - 0s 977us/step - loss: 39755.4883\n",
            "Epoch 31/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 24488.3496\n",
            "Epoch 32/100\n",
            "237/237 [==============================] - 0s 897us/step - loss: 25635.1602\n",
            "Epoch 33/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 26693.0156\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 26142.1133\n",
            "Epoch 35/100\n",
            "237/237 [==============================] - 0s 941us/step - loss: 23984.1250\n",
            "Epoch 36/100\n",
            "237/237 [==============================] - 0s 987us/step - loss: 26236.7305\n",
            "Epoch 37/100\n",
            "237/237 [==============================] - 0s 953us/step - loss: 28249.0547\n",
            "Epoch 38/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 27736.7637\n",
            "Epoch 39/100\n",
            "237/237 [==============================] - 0s 993us/step - loss: 29149.0762\n",
            "Epoch 40/100\n",
            "237/237 [==============================] - 0s 990us/step - loss: 24713.1797\n",
            "Epoch 41/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 24765.3086\n",
            "Epoch 42/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 28515.5508\n",
            "Epoch 43/100\n",
            "237/237 [==============================] - 0s 968us/step - loss: 21889.8359\n",
            "Epoch 44/100\n",
            "237/237 [==============================] - 0s 901us/step - loss: 24750.5977\n",
            "Epoch 45/100\n",
            "237/237 [==============================] - 0s 965us/step - loss: 23440.7598\n",
            "Epoch 46/100\n",
            "237/237 [==============================] - 0s 959us/step - loss: 31058.4766\n",
            "Epoch 47/100\n",
            "237/237 [==============================] - 0s 1000us/step - loss: 24393.0508\n",
            "Epoch 48/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 23059.4023\n",
            "Epoch 49/100\n",
            "237/237 [==============================] - 0s 982us/step - loss: 26826.5547\n",
            "Epoch 50/100\n",
            "237/237 [==============================] - 0s 964us/step - loss: 24265.7188\n",
            "Epoch 51/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 24160.7773\n",
            "Epoch 52/100\n",
            "237/237 [==============================] - 0s 948us/step - loss: 24508.0410\n",
            "Epoch 53/100\n",
            "237/237 [==============================] - 0s 998us/step - loss: 22835.9766\n",
            "Epoch 54/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 25197.2051\n",
            "Epoch 55/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 24373.1582\n",
            "Epoch 56/100\n",
            "237/237 [==============================] - 0s 989us/step - loss: 22823.0645\n",
            "Epoch 57/100\n",
            "237/237 [==============================] - 0s 970us/step - loss: 26023.9160\n",
            "Epoch 58/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 24749.4668\n",
            "Epoch 59/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 24476.6504\n",
            "Epoch 60/100\n",
            "237/237 [==============================] - 0s 985us/step - loss: 22827.7930\n",
            "Epoch 61/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 22846.4316\n",
            "Epoch 62/100\n",
            "237/237 [==============================] - 0s 957us/step - loss: 21631.4121\n",
            "Epoch 63/100\n",
            "237/237 [==============================] - 0s 984us/step - loss: 21952.9746\n",
            "Epoch 64/100\n",
            "237/237 [==============================] - 0s 989us/step - loss: 23865.1895\n",
            "Epoch 65/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 21782.2188\n",
            "Epoch 66/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 23503.5898\n",
            "Epoch 67/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 22992.7910\n",
            "Epoch 68/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 27820.0723\n",
            "Epoch 69/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 20308.8105\n",
            "Epoch 70/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 21311.4434\n",
            "Epoch 71/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 28111.1465\n",
            "Epoch 72/100\n",
            "237/237 [==============================] - 0s 968us/step - loss: 26974.8438\n",
            "Epoch 73/100\n",
            "237/237 [==============================] - 0s 965us/step - loss: 21356.7969\n",
            "Epoch 74/100\n",
            "237/237 [==============================] - 0s 969us/step - loss: 21509.5254\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 20560.5195\n",
            "Epoch 76/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 19216.1035\n",
            "Epoch 77/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 21717.2148\n",
            "Epoch 78/100\n",
            "237/237 [==============================] - 0s 980us/step - loss: 22767.2793\n",
            "Epoch 79/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 21464.6035\n",
            "Epoch 80/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 21909.1816\n",
            "Epoch 81/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 22644.2988\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 20534.6855\n",
            "Epoch 83/100\n",
            "237/237 [==============================] - 0s 989us/step - loss: 21054.0840\n",
            "Epoch 84/100\n",
            "237/237 [==============================] - 0s 973us/step - loss: 23120.0586\n",
            "Epoch 85/100\n",
            "237/237 [==============================] - 0s 978us/step - loss: 20982.3945\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 20810.5078\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - 0s 973us/step - loss: 21319.1758\n",
            "Epoch 88/100\n",
            "237/237 [==============================] - 0s 955us/step - loss: 24115.4082\n",
            "Epoch 89/100\n",
            "237/237 [==============================] - 0s 946us/step - loss: 22501.3262\n",
            "Epoch 90/100\n",
            "237/237 [==============================] - 0s 928us/step - loss: 21835.6406\n",
            "Epoch 91/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 21482.7793\n",
            "Epoch 92/100\n",
            "237/237 [==============================] - 0s 954us/step - loss: 21236.1562\n",
            "Epoch 93/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 19901.5371\n",
            "Epoch 94/100\n",
            "237/237 [==============================] - 0s 983us/step - loss: 25491.3887\n",
            "Epoch 95/100\n",
            "237/237 [==============================] - 0s 949us/step - loss: 21690.8301\n",
            "Epoch 96/100\n",
            "237/237 [==============================] - 0s 998us/step - loss: 18871.7930\n",
            "Epoch 97/100\n",
            "237/237 [==============================] - 0s 975us/step - loss: 20633.2969\n",
            "Epoch 98/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 20039.9141\n",
            "Epoch 99/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 19460.7656\n",
            "Epoch 100/100\n",
            "237/237 [==============================] - 0s 1ms/step - loss: 20984.9902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f114695ef20>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "#After defining the model, we now train it against the training set:\n",
        "model.fit(X_scaled_train, y_train, epochs=100, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sEHprLTpwwz",
        "outputId": "eb169783-8883-4cb2-8a50-b7dc6949be76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n",
            "[[23568.459]\n",
            " [23581.818]\n",
            " [23084.455]\n",
            " [23764.826]\n",
            " [23868.143]\n",
            " [24108.541]\n",
            " [24148.73 ]\n",
            " [24271.074]\n",
            " [24262.178]\n",
            " [24219.229]\n",
            " [24404.273]\n",
            " [24519.432]\n",
            " [24725.88 ]\n",
            " [24980.195]\n",
            " [24748.115]\n",
            " [24913.977]\n",
            " [24897.414]\n",
            " [25015.229]\n",
            " [24777.197]\n",
            " [24970.834]\n",
            " [25306.322]\n",
            " [25220.104]\n",
            " [25344.215]\n",
            " [25506.566]\n",
            " [25686.033]\n",
            " [25628.234]\n",
            " [25446.389]\n",
            " [25431.162]\n",
            " [25455.63 ]\n",
            " [25801.53 ]\n",
            " [25891.223]\n",
            " [25812.998]\n",
            " [26221.51 ]\n",
            " [26252.818]\n",
            " [26301.613]\n",
            " [26226.363]\n",
            " [26434.59 ]\n",
            " [26491.94 ]\n",
            " [26417.662]\n",
            " [26350.385]\n",
            " [26307.666]\n",
            " [26429.732]\n",
            " [26193.303]\n",
            " [26183.068]\n",
            " [26060.373]\n",
            " [25819.814]\n",
            " [25718.654]\n",
            " [25922.754]\n",
            " [25937.346]\n",
            " [26057.467]\n",
            " [26072.217]\n",
            " [26053.018]\n",
            " [26200.684]\n",
            " [26192.643]\n",
            " [26013.494]\n",
            " [26175.97 ]\n",
            " [25897.889]\n",
            " [25957.127]\n",
            " [26091.809]\n",
            " [26053.115]\n",
            " [26101.896]\n",
            " [26382.764]\n",
            " [26695.996]\n",
            " [26624.033]\n",
            " [26657.375]\n",
            " [26799.13 ]\n",
            " [26803.264]\n",
            " [26685.123]\n",
            " [26567.418]\n",
            " [26612.121]\n",
            " [26639.717]\n",
            " [26785.547]\n",
            " [26768.498]\n",
            " [26835.846]\n",
            " [26796.973]\n",
            " [26887.58 ]\n",
            " [26866.846]\n",
            " [26996.184]\n",
            " [26912.863]\n",
            " [26794.783]\n",
            " [26907.678]\n",
            " [26967.385]\n",
            " [26957.545]\n",
            " [26838.518]\n",
            " [26742.732]\n",
            " [26820.525]\n",
            " [26699.37 ]\n",
            " [26377.213]\n",
            " [26405.916]\n",
            " [26197.088]\n",
            " [26183.488]\n",
            " [25677.354]\n",
            " [25915.275]\n",
            " [26006.68 ]\n",
            " [26195.428]\n",
            " [26090.107]\n",
            " [26080.928]\n",
            " [26264.967]\n",
            " [26131.465]\n",
            " [25856.535]\n",
            " [26000.578]\n",
            " [25713.152]\n",
            " [25459.03 ]\n",
            " [25490.982]\n",
            " [25187.045]\n",
            " [25205.95 ]\n",
            " [25716.338]\n",
            " [25913.975]\n",
            " [26109.322]\n",
            " [26418.408]\n",
            " [26538.227]\n",
            " [26475.514]\n",
            " [26400.346]\n",
            " [26474.408]\n",
            " [26462.736]\n",
            " [26531.049]\n",
            " [26844.342]\n",
            " [26932.137]\n",
            " [27128.79 ]\n",
            " [27029.855]\n",
            " [27084.12 ]\n",
            " [26928.941]\n",
            " [26905.225]\n",
            " [26900.998]\n",
            " [26964.133]\n",
            " [27081.418]\n",
            " [27113.285]\n",
            " [27272.395]\n",
            " [27192.287]\n",
            " [27183.178]\n",
            " [27210.97 ]\n",
            " [27339.031]\n",
            " [27514.94 ]\n",
            " [27755.486]\n",
            " [27803.408]\n",
            " [27779.586]\n",
            " [27665.773]\n",
            " [27648.342]\n",
            " [27592.541]\n",
            " [27601.955]\n",
            " [27714.668]\n",
            " [27645.889]\n",
            " [27565.746]\n",
            " [27620.252]\n",
            " [27627.162]\n",
            " [27570.78 ]\n",
            " [27278.244]\n",
            " [27051.354]\n",
            " [26815.021]\n",
            " [26144.516]\n",
            " [26349.695]\n",
            " [26304.08 ]\n",
            " [26713.596]\n",
            " [26590.443]\n",
            " [26307.582]\n",
            " [26563.795]\n",
            " [25891.99 ]\n",
            " [25978.332]\n",
            " [26303.082]\n",
            " [26531.61 ]\n",
            " [26397.676]\n",
            " [26655.596]\n",
            " [26634.045]\n",
            " [26087.127]\n",
            " [26333.998]\n",
            " [26168.787]\n",
            " [26418.084]\n",
            " [26773.854]\n",
            " [26340.78 ]\n",
            " [26332.092]\n",
            " [26589.473]\n",
            " [26917.586]\n",
            " [27058.84 ]\n",
            " [27345.1  ]\n",
            " [27371.453]\n",
            " [27625.402]\n",
            " [27708.482]\n",
            " [27711.432]\n",
            " [27566.086]\n",
            " [27609.578]\n",
            " [27657.13 ]\n",
            " [27655.969]\n",
            " [27334.63 ]\n",
            " [27408.69 ]\n",
            " [27276.768]\n",
            " [27401.705]\n",
            " [27351.232]\n",
            " [27360.855]\n",
            " [27454.238]\n",
            " [27002.049]\n",
            " [26508.113]\n",
            " [26611.475]\n",
            " [26966.232]\n",
            " [26813.217]\n",
            " [26595.303]\n",
            " [26788.357]\n",
            " [26968.107]\n",
            " [27230.545]\n",
            " [27209.828]\n",
            " [27429.133]\n",
            " [27427.277]\n",
            " [27443.355]\n",
            " [27210.98 ]\n",
            " [27241.49 ]\n",
            " [27219.982]\n",
            " [27242.623]\n",
            " [27184.191]\n",
            " [27343.574]\n",
            " [27489.877]\n",
            " [27478.775]\n",
            " [27573.307]\n",
            " [27468.365]\n",
            " [27760.408]\n",
            " [27889.582]\n",
            " [27905.943]\n",
            " [27934.244]\n",
            " [28109.518]\n",
            " [28056.084]\n",
            " [28074.885]\n",
            " [28088.424]\n",
            " [28143.879]\n",
            " [28184.207]\n",
            " [28401.98 ]\n",
            " [28461.31 ]\n",
            " [28359.57 ]\n",
            " [28223.295]\n",
            " [28223.342]\n",
            " [28331.613]\n",
            " [28490.686]\n",
            " [28551.014]\n",
            " [28589.172]\n",
            " [28524.709]\n",
            " [28188.555]\n",
            " [27969.852]\n",
            " [28209.559]\n",
            " [28194.367]\n",
            " [28481.84 ]\n",
            " [28393.316]\n",
            " [28369.996]\n",
            " [28378.432]\n",
            " [28562.467]\n",
            " [28612.438]\n",
            " [28697.389]\n",
            " [28722.242]\n",
            " [28699.521]\n",
            " [28879.877]\n",
            " [28815.318]\n",
            " [28933.525]\n",
            " [28913.166]\n",
            " [29021.482]\n",
            " [29021.248]\n",
            " [28945.932]]\n"
          ]
        }
      ],
      "source": [
        "predictions_3=model.predict(X_scaled_test)\n",
        "print(predictions_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzheT9J_qSGI",
        "outputId": "9290efdb-7f04-428d-c7e3-ca20697b53c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 172203.301\n"
          ]
        }
      ],
      "source": [
        "#Finally, we use the trained model to predict the testing data and display metrics:\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(f'MSE: {mean_squared_error(y_test,predictions_3):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fcw-grqqVIJ",
        "outputId": "2919fb4e-07f6-4c5e-d6de-88db39257948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 370.499\n"
          ]
        }
      ],
      "source": [
        "print(f'MAE: {mean_absolute_error(y_test,predictions_3):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB5OyvPzqXdO",
        "outputId": "aabeaed8-9c6a-4be6-e500-94b852929bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2: 0.852\n"
          ]
        }
      ],
      "source": [
        "print(f'R^2: {r2_score(y_test, predictions_3):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKn392g2qZZN"
      },
      "outputs": [],
      "source": [
        "from tensorboard.plugins.hparams import api as hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDEhzmhpqben"
      },
      "outputs": [],
      "source": [
        "HP_HIDDEN = hp.HParam('hidden_size', hp.Discrete([64, 32,16]))\n",
        "HP_EPOCHS = hp.HParam('epochs', hp.Discrete([300, 1000]))\n",
        "HP_LEARNING_RATE= hp.HParam('learning_rate', hp.RealInterval (0.01, 0.4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Eezks79qdL1"
      },
      "outputs": [],
      "source": [
        "def train_test_model(hparams, logdir):\n",
        "\n",
        "    model = Sequential([Dense(units=hparams[HP_HIDDEN], activation='relu'),Dense(units=1)])\n",
        "\n",
        "    model.compile(loss='mean_squared_error',optimizer=tf.keras.optimizers.Adam(hparams[HP_LEARNING_RATE]),metrics=['mean_squared_error'])\n",
        "\n",
        "    model.fit(X_scaled_train, y_train,validation_data=(X_scaled_test, y_test), epochs=hparams [HP_EPOCHS], verbose=False, callbacks=[tf.keras.callbacks. TensorBoard (logdir), hp.KerasCallback(logdir, hparams), tf.keras.callbacks. EarlyStopping( monitor= 'val_loss', min_delta=0, patience=200, verbose=0, mode= 'auto',)],)\n",
        "    mse=model.evaluate(X_scaled_test, y_test)[1]\n",
        "\n",
        "\n",
        "    pred = model.predict(X_scaled_test)\n",
        "\n",
        "    r2 = r2_score (y_test, pred)\n",
        "\n",
        "    return mse, r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5HV56DiqfH8"
      },
      "outputs": [],
      "source": [
        "def run (hparams, logdir):\n",
        "    with tf.summary.create_file_writer (logdir).as_default():\n",
        "        hp.hparams_config(hparams=[HP_HIDDEN, HP_EPOCHS, HP_LEARNING_RATE],\n",
        "                          metrics=[hp.Metric('mean_squared_error', display_name='mse'),\n",
        "                                   hp.Metric('r2', display_name='r2')])\n",
        "        mse, r2 = train_test_model(hparams, logdir)\n",
        "        tf.summary.scalar('mean_squared_error', mse, step=1)\n",
        "        tf.summary.scalar('r2', r2, step=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKNEOMiLqhMb",
        "outputId": "23cb0768-e405-4d4f-e26f-74d175510619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Starting trial: run-1\n",
            "{'hidden_size': 16, 'epochs': 300, 'learning_rate': 0.01}\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 48153.4453 - mean_squared_error: 48153.4453\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "-- Starting trial: run-2\n",
            "{'hidden_size': 16, 'epochs': 300, 'learning_rate': 0.11}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 80204.0078 - mean_squared_error: 80204.0078\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-3\n",
            "{'hidden_size': 16, 'epochs': 300, 'learning_rate': 0.21}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 95444.7578 - mean_squared_error: 95444.7578\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-4\n",
            "{'hidden_size': 16, 'epochs': 300, 'learning_rate': 0.3}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 93451.2578 - mean_squared_error: 93451.2578\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-5\n",
            "{'hidden_size': 16, 'epochs': 300, 'learning_rate': 0.4}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 121729.5781 - mean_squared_error: 121729.5781\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "-- Starting trial: run-6\n",
            "{'hidden_size': 16, 'epochs': 1000, 'learning_rate': 0.01}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 53351.5273 - mean_squared_error: 53351.5273\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-7\n",
            "{'hidden_size': 16, 'epochs': 1000, 'learning_rate': 0.11}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 110473.5703 - mean_squared_error: 110473.5703\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-8\n",
            "{'hidden_size': 16, 'epochs': 1000, 'learning_rate': 0.21}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 37076.5859 - mean_squared_error: 37076.5859\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-9\n",
            "{'hidden_size': 16, 'epochs': 1000, 'learning_rate': 0.3}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 57526.9180 - mean_squared_error: 57526.9180\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-10\n",
            "{'hidden_size': 16, 'epochs': 1000, 'learning_rate': 0.4}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 95617.5547 - mean_squared_error: 95617.5547\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-11\n",
            "{'hidden_size': 32, 'epochs': 300, 'learning_rate': 0.01}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 79463.3828 - mean_squared_error: 79463.3828\n",
            "8/8 [==============================] - 0s 994us/step\n",
            "-- Starting trial: run-12\n",
            "{'hidden_size': 32, 'epochs': 300, 'learning_rate': 0.11}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 94811.1641 - mean_squared_error: 94811.1641\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-13\n",
            "{'hidden_size': 32, 'epochs': 300, 'learning_rate': 0.21}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 84643.8594 - mean_squared_error: 84643.8594\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-14\n",
            "{'hidden_size': 32, 'epochs': 300, 'learning_rate': 0.3}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 78200.0625 - mean_squared_error: 78200.0625\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-15\n",
            "{'hidden_size': 32, 'epochs': 300, 'learning_rate': 0.4}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 88447.3594 - mean_squared_error: 88447.3594\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-16\n",
            "{'hidden_size': 32, 'epochs': 1000, 'learning_rate': 0.01}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 92646.7266 - mean_squared_error: 92646.7266\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-17\n",
            "{'hidden_size': 32, 'epochs': 1000, 'learning_rate': 0.11}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 70690.2578 - mean_squared_error: 70690.2578\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-18\n",
            "{'hidden_size': 32, 'epochs': 1000, 'learning_rate': 0.21}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 45080.6641 - mean_squared_error: 45080.6641\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-19\n",
            "{'hidden_size': 32, 'epochs': 1000, 'learning_rate': 0.3}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 43870.3867 - mean_squared_error: 43870.3867\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-20\n",
            "{'hidden_size': 32, 'epochs': 1000, 'learning_rate': 0.4}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 35261.3438 - mean_squared_error: 35261.3438\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-21\n",
            "{'hidden_size': 64, 'epochs': 300, 'learning_rate': 0.01}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 112200.6172 - mean_squared_error: 112200.6172\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-22\n",
            "{'hidden_size': 64, 'epochs': 300, 'learning_rate': 0.11}\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 218392.3125 - mean_squared_error: 218392.3125\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-23\n",
            "{'hidden_size': 64, 'epochs': 300, 'learning_rate': 0.21}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 73232.1719 - mean_squared_error: 73232.1719\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-24\n",
            "{'hidden_size': 64, 'epochs': 300, 'learning_rate': 0.3}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 99161.0391 - mean_squared_error: 99161.0391\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-25\n",
            "{'hidden_size': 64, 'epochs': 300, 'learning_rate': 0.4}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 84366.1875 - mean_squared_error: 84366.1875\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-26\n",
            "{'hidden_size': 64, 'epochs': 1000, 'learning_rate': 0.01}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 106353.5938 - mean_squared_error: 106353.5938\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-27\n",
            "{'hidden_size': 64, 'epochs': 1000, 'learning_rate': 0.11}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 118578.3906 - mean_squared_error: 118578.3906\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-28\n",
            "{'hidden_size': 64, 'epochs': 1000, 'learning_rate': 0.21}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 88317.4609 - mean_squared_error: 88317.4609\n",
            "8/8 [==============================] - 0s 1ms/step\n",
            "-- Starting trial: run-29\n",
            "{'hidden_size': 64, 'epochs': 1000, 'learning_rate': 0.3}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 43040.2344 - mean_squared_error: 43040.2344\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "-- Starting trial: run-30\n",
            "{'hidden_size': 64, 'epochs': 1000, 'learning_rate': 0.4}\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 94014.0547 - mean_squared_error: 94014.0547\n",
            "8/8 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "session_num=1\n",
        "for hidden in HP_HIDDEN.domain.values:\n",
        "    for epochs in HP_EPOCHS.domain.values:\n",
        "        for learning_rate in tf.linspace(HP_LEARNING_RATE.domain.min_value, HP_LEARNING_RATE.domain.max_value, 5):\n",
        "                hparams ={HP_HIDDEN: hidden,HP_EPOCHS: epochs,HP_LEARNING_RATE:float(\"%.2f\"%float (learning_rate)),}\n",
        "\n",
        "                run_name = \"run-%d\" % session_num\n",
        "                print('-- Starting trial: %s' % run_name)\n",
        "                print({h.name: hparams[h] for h in hparams})\n",
        "                run(hparams, 'logs/hparam_tuning/' + run_name)\n",
        "                session_num+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After above process, we can get some log files which is saved in our folder.Then we have to open anaconda prompt, in anaconda prompt we have to provide path of log file, then we will get http link,now we have to link in google. There we can observe the results and also we find the best accurate results of our model.\n",
        "I got 0.96962 of r2 square value and 35261 mse value,when hidden_size is 32.000, epochs=1000 and learning rate=0.4."
      ],
      "metadata": {
        "id": "P2-PwabkX0_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r logs.zip logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHu8LqMEZ1fR",
        "outputId": "0ea1c3c8-d3a5-4b7b-9018-233b18f09f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: logs/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-9/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-9/events.out.tfevents.1687236650.94c8ce8a5f5f.389.176.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-9/events.out.tfevents.1687230652.94c8ce8a5f5f.389.32.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-9/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-9/train/events.out.tfevents.1687230652.94c8ce8a5f5f.389.34.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-9/train/events.out.tfevents.1687236650.94c8ce8a5f5f.389.178.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-9/events.out.tfevents.1687230652.94c8ce8a5f5f.389.33.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-9/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-9/validation/events.out.tfevents.1687236651.94c8ce8a5f5f.389.179.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-9/validation/events.out.tfevents.1687230653.94c8ce8a5f5f.389.35.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-9/events.out.tfevents.1687236650.94c8ce8a5f5f.389.177.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-18/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-18/events.out.tfevents.1687231664.94c8ce8a5f5f.389.69.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-18/events.out.tfevents.1687231664.94c8ce8a5f5f.389.68.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-18/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-18/train/events.out.tfevents.1687231664.94c8ce8a5f5f.389.70.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-18/train/events.out.tfevents.1687237673.94c8ce8a5f5f.389.214.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-18/events.out.tfevents.1687237673.94c8ce8a5f5f.389.213.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-18/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-18/validation/events.out.tfevents.1687237673.94c8ce8a5f5f.389.215.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-18/validation/events.out.tfevents.1687231664.94c8ce8a5f5f.389.71.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-18/events.out.tfevents.1687237673.94c8ce8a5f5f.389.212.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-13/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-13/events.out.tfevents.1687237108.94c8ce8a5f5f.389.192.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-13/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-13/train/events.out.tfevents.1687231214.94c8ce8a5f5f.389.50.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-13/train/events.out.tfevents.1687237108.94c8ce8a5f5f.389.194.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-13/events.out.tfevents.1687237108.94c8ce8a5f5f.389.193.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-13/events.out.tfevents.1687231214.94c8ce8a5f5f.389.48.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-13/events.out.tfevents.1687231214.94c8ce8a5f5f.389.49.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-13/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-13/validation/events.out.tfevents.1687231215.94c8ce8a5f5f.389.51.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-13/validation/events.out.tfevents.1687237109.94c8ce8a5f5f.389.195.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-17/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-17/events.out.tfevents.1687231521.94c8ce8a5f5f.389.64.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-17/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-17/train/events.out.tfevents.1687231521.94c8ce8a5f5f.389.66.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-17/train/events.out.tfevents.1687237552.94c8ce8a5f5f.389.210.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-17/events.out.tfevents.1687231521.94c8ce8a5f5f.389.65.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-17/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-17/validation/events.out.tfevents.1687237553.94c8ce8a5f5f.389.211.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-17/validation/events.out.tfevents.1687231522.94c8ce8a5f5f.389.67.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-17/events.out.tfevents.1687237552.94c8ce8a5f5f.389.208.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-17/events.out.tfevents.1687237552.94c8ce8a5f5f.389.209.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-22/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-22/events.out.tfevents.1687238288.94c8ce8a5f5f.389.228.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-22/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-22/train/events.out.tfevents.1687232241.94c8ce8a5f5f.389.86.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-22/train/events.out.tfevents.1687238288.94c8ce8a5f5f.389.230.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-22/events.out.tfevents.1687232241.94c8ce8a5f5f.389.85.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-22/events.out.tfevents.1687238288.94c8ce8a5f5f.389.229.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-22/events.out.tfevents.1687232241.94c8ce8a5f5f.389.84.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-22/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-22/validation/events.out.tfevents.1687232241.94c8ce8a5f5f.389.87.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-22/validation/events.out.tfevents.1687238288.94c8ce8a5f5f.389.231.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-27/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-27/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-27/train/events.out.tfevents.1687238700.94c8ce8a5f5f.389.250.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-27/train/events.out.tfevents.1687232737.94c8ce8a5f5f.389.106.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-27/events.out.tfevents.1687238700.94c8ce8a5f5f.389.248.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-27/events.out.tfevents.1687238700.94c8ce8a5f5f.389.249.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-27/events.out.tfevents.1687232737.94c8ce8a5f5f.389.105.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-27/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-27/validation/events.out.tfevents.1687232738.94c8ce8a5f5f.389.107.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-27/validation/events.out.tfevents.1687238701.94c8ce8a5f5f.389.251.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-27/events.out.tfevents.1687232737.94c8ce8a5f5f.389.104.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-7/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-7/events.out.tfevents.1687230362.94c8ce8a5f5f.389.25.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-7/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-7/train/events.out.tfevents.1687236241.94c8ce8a5f5f.389.170.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-7/train/events.out.tfevents.1687230362.94c8ce8a5f5f.389.26.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-7/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-7/validation/events.out.tfevents.1687236242.94c8ce8a5f5f.389.171.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-7/validation/events.out.tfevents.1687230363.94c8ce8a5f5f.389.27.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-7/events.out.tfevents.1687236241.94c8ce8a5f5f.389.169.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-7/events.out.tfevents.1687230362.94c8ce8a5f5f.389.24.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-7/events.out.tfevents.1687236241.94c8ce8a5f5f.389.168.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-10/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-10/events.out.tfevents.1687230842.94c8ce8a5f5f.389.37.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-10/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-10/train/events.out.tfevents.1687230842.94c8ce8a5f5f.389.38.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-10/train/events.out.tfevents.1687236730.94c8ce8a5f5f.389.182.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-10/events.out.tfevents.1687236730.94c8ce8a5f5f.389.181.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-10/events.out.tfevents.1687236730.94c8ce8a5f5f.389.180.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-10/events.out.tfevents.1687230842.94c8ce8a5f5f.389.36.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-10/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-10/validation/events.out.tfevents.1687230843.94c8ce8a5f5f.389.39.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-10/validation/events.out.tfevents.1687236731.94c8ce8a5f5f.389.183.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-28/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-28/events.out.tfevents.1687232880.94c8ce8a5f5f.389.108.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-28/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-28/train/events.out.tfevents.1687238776.94c8ce8a5f5f.389.254.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-28/train/events.out.tfevents.1687232880.94c8ce8a5f5f.389.110.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-28/events.out.tfevents.1687232880.94c8ce8a5f5f.389.109.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-28/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-28/validation/events.out.tfevents.1687238777.94c8ce8a5f5f.389.255.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-28/validation/events.out.tfevents.1687232880.94c8ce8a5f5f.389.111.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-28/events.out.tfevents.1687238776.94c8ce8a5f5f.389.253.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-28/events.out.tfevents.1687238776.94c8ce8a5f5f.389.252.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-19/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-19/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-19/train/events.out.tfevents.1687231810.94c8ce8a5f5f.389.74.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-19/train/events.out.tfevents.1687237870.94c8ce8a5f5f.389.218.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-19/events.out.tfevents.1687231810.94c8ce8a5f5f.389.72.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-19/events.out.tfevents.1687231810.94c8ce8a5f5f.389.73.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-19/events.out.tfevents.1687237870.94c8ce8a5f5f.389.217.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-19/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-19/validation/events.out.tfevents.1687237871.94c8ce8a5f5f.389.219.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-19/validation/events.out.tfevents.1687231810.94c8ce8a5f5f.389.75.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-19/events.out.tfevents.1687237870.94c8ce8a5f5f.389.216.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-6/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-6/events.out.tfevents.1687230160.94c8ce8a5f5f.389.21.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-6/events.out.tfevents.1687230160.94c8ce8a5f5f.389.20.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-6/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-6/train/events.out.tfevents.1687236099.94c8ce8a5f5f.389.166.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-6/train/events.out.tfevents.1687235472.94c8ce8a5f5f.389.142.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-6/train/events.out.tfevents.1687230160.94c8ce8a5f5f.389.22.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-6/events.out.tfevents.1687236099.94c8ce8a5f5f.389.164.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-6/events.out.tfevents.1687235472.94c8ce8a5f5f.389.140.v2 (deflated 17%)\n",
            "  adding: logs/hparam_tuning/run-6/events.out.tfevents.1687235472.94c8ce8a5f5f.389.141.v2 (deflated 11%)\n",
            "  adding: logs/hparam_tuning/run-6/events.out.tfevents.1687236099.94c8ce8a5f5f.389.165.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-6/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-6/validation/events.out.tfevents.1687235473.94c8ce8a5f5f.389.143.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-6/validation/events.out.tfevents.1687230161.94c8ce8a5f5f.389.23.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-6/validation/events.out.tfevents.1687236099.94c8ce8a5f5f.389.167.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-15/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-15/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-15/train/events.out.tfevents.1687231369.94c8ce8a5f5f.389.58.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-15/train/events.out.tfevents.1687237273.94c8ce8a5f5f.389.202.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-15/events.out.tfevents.1687237273.94c8ce8a5f5f.389.201.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-15/events.out.tfevents.1687237273.94c8ce8a5f5f.389.200.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-15/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-15/validation/events.out.tfevents.1687231369.94c8ce8a5f5f.389.59.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-15/validation/events.out.tfevents.1687237273.94c8ce8a5f5f.389.203.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-15/events.out.tfevents.1687231369.94c8ce8a5f5f.389.56.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-15/events.out.tfevents.1687231369.94c8ce8a5f5f.389.57.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-21/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-21/events.out.tfevents.1687238217.94c8ce8a5f5f.389.224.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-21/events.out.tfevents.1687232158.94c8ce8a5f5f.389.81.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-21/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-21/train/events.out.tfevents.1687232158.94c8ce8a5f5f.389.82.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-21/train/events.out.tfevents.1687238217.94c8ce8a5f5f.389.226.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-21/events.out.tfevents.1687238217.94c8ce8a5f5f.389.225.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-21/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-21/validation/events.out.tfevents.1687238217.94c8ce8a5f5f.389.227.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-21/validation/events.out.tfevents.1687232159.94c8ce8a5f5f.389.83.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-21/events.out.tfevents.1687232158.94c8ce8a5f5f.389.80.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-4/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-4/events.out.tfevents.1687235942.94c8ce8a5f5f.389.156.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-4/events.out.tfevents.1687235319.94c8ce8a5f5f.389.133.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-4/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-4/train/events.out.tfevents.1687235319.94c8ce8a5f5f.389.134.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-4/train/events.out.tfevents.1687235942.94c8ce8a5f5f.389.158.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-4/train/events.out.tfevents.1687230007.94c8ce8a5f5f.389.14.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-4/events.out.tfevents.1687235942.94c8ce8a5f5f.389.157.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-4/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-4/validation/events.out.tfevents.1687230008.94c8ce8a5f5f.389.15.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-4/validation/events.out.tfevents.1687235320.94c8ce8a5f5f.389.135.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-4/validation/events.out.tfevents.1687235943.94c8ce8a5f5f.389.159.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-4/events.out.tfevents.1687230007.94c8ce8a5f5f.389.12.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-4/events.out.tfevents.1687230007.94c8ce8a5f5f.389.13.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-4/events.out.tfevents.1687235319.94c8ce8a5f5f.389.132.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-11/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-11/events.out.tfevents.1687231073.94c8ce8a5f5f.389.41.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-11/events.out.tfevents.1687231073.94c8ce8a5f5f.389.40.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-11/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-11/train/events.out.tfevents.1687231073.94c8ce8a5f5f.389.42.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-11/train/events.out.tfevents.1687236954.94c8ce8a5f5f.389.186.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-11/events.out.tfevents.1687236954.94c8ce8a5f5f.389.185.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-11/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-11/validation/events.out.tfevents.1687231074.94c8ce8a5f5f.389.43.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-11/validation/events.out.tfevents.1687236954.94c8ce8a5f5f.389.187.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-11/events.out.tfevents.1687236954.94c8ce8a5f5f.389.184.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-23/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-23/events.out.tfevents.1687232310.94c8ce8a5f5f.389.89.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-23/events.out.tfevents.1687238370.94c8ce8a5f5f.389.232.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-23/events.out.tfevents.1687238370.94c8ce8a5f5f.389.233.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-23/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-23/train/events.out.tfevents.1687232310.94c8ce8a5f5f.389.90.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-23/train/events.out.tfevents.1687238370.94c8ce8a5f5f.389.234.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-23/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-23/validation/events.out.tfevents.1687232311.94c8ce8a5f5f.389.91.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-23/validation/events.out.tfevents.1687238371.94c8ce8a5f5f.389.235.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-23/events.out.tfevents.1687232310.94c8ce8a5f5f.389.88.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-14/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-14/events.out.tfevents.1687237190.94c8ce8a5f5f.389.196.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-14/events.out.tfevents.1687231286.94c8ce8a5f5f.389.52.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-14/events.out.tfevents.1687237190.94c8ce8a5f5f.389.197.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-14/events.out.tfevents.1687231286.94c8ce8a5f5f.389.53.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-14/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-14/train/events.out.tfevents.1687237190.94c8ce8a5f5f.389.198.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-14/train/events.out.tfevents.1687231286.94c8ce8a5f5f.389.54.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-14/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-14/validation/events.out.tfevents.1687231287.94c8ce8a5f5f.389.55.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-14/validation/events.out.tfevents.1687237191.94c8ce8a5f5f.389.199.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-3/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-3/events.out.tfevents.1687229937.94c8ce8a5f5f.389.9.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-3/events.out.tfevents.1687235860.94c8ce8a5f5f.389.152.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-3/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-3/train/events.out.tfevents.1687235860.94c8ce8a5f5f.389.154.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-3/train/events.out.tfevents.1687229937.94c8ce8a5f5f.389.10.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-3/train/events.out.tfevents.1687235248.94c8ce8a5f5f.389.130.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-3/events.out.tfevents.1687235248.94c8ce8a5f5f.389.129.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-3/events.out.tfevents.1687235860.94c8ce8a5f5f.389.153.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-3/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-3/validation/events.out.tfevents.1687235248.94c8ce8a5f5f.389.131.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-3/validation/events.out.tfevents.1687235860.94c8ce8a5f5f.389.155.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-3/validation/events.out.tfevents.1687229938.94c8ce8a5f5f.389.11.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-3/events.out.tfevents.1687235248.94c8ce8a5f5f.389.128.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-3/events.out.tfevents.1687229937.94c8ce8a5f5f.389.8.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-5/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-5/events.out.tfevents.1687236025.94c8ce8a5f5f.389.161.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-5/events.out.tfevents.1687236025.94c8ce8a5f5f.389.160.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-5/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-5/train/events.out.tfevents.1687236025.94c8ce8a5f5f.389.162.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-5/train/events.out.tfevents.1687235390.94c8ce8a5f5f.389.138.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-5/train/events.out.tfevents.1687230077.94c8ce8a5f5f.389.18.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-5/events.out.tfevents.1687235390.94c8ce8a5f5f.389.136.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-5/events.out.tfevents.1687230077.94c8ce8a5f5f.389.17.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-5/events.out.tfevents.1687230077.94c8ce8a5f5f.389.16.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-5/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-5/validation/events.out.tfevents.1687236025.94c8ce8a5f5f.389.163.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-5/validation/events.out.tfevents.1687230078.94c8ce8a5f5f.389.19.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-5/validation/events.out.tfevents.1687235390.94c8ce8a5f5f.389.139.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-5/events.out.tfevents.1687235390.94c8ce8a5f5f.389.137.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-2/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-2/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-2/train/events.out.tfevents.1687229855.94c8ce8a5f5f.389.6.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-2/train/events.out.tfevents.1687235777.94c8ce8a5f5f.389.150.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-2/train/events.out.tfevents.1687235174.94c8ce8a5f5f.389.126.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-2/events.out.tfevents.1687235777.94c8ce8a5f5f.389.149.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-2/events.out.tfevents.1687235174.94c8ce8a5f5f.389.124.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-2/events.out.tfevents.1687229855.94c8ce8a5f5f.389.4.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-2/events.out.tfevents.1687235777.94c8ce8a5f5f.389.148.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-2/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-2/validation/events.out.tfevents.1687235778.94c8ce8a5f5f.389.151.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-2/validation/events.out.tfevents.1687229855.94c8ce8a5f5f.389.7.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-2/validation/events.out.tfevents.1687235174.94c8ce8a5f5f.389.127.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-2/events.out.tfevents.1687235174.94c8ce8a5f5f.389.125.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-2/events.out.tfevents.1687229855.94c8ce8a5f5f.389.5.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-1/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-1/events.out.tfevents.1687235701.94c8ce8a5f5f.389.144.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-1/events.out.tfevents.1687235098.94c8ce8a5f5f.389.121.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-1/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-1/train/events.out.tfevents.1687229786.94c8ce8a5f5f.389.2.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-1/train/events.out.tfevents.1687235098.94c8ce8a5f5f.389.122.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-1/train/events.out.tfevents.1687235701.94c8ce8a5f5f.389.146.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-1/events.out.tfevents.1687235701.94c8ce8a5f5f.389.145.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-1/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-1/validation/events.out.tfevents.1687235099.94c8ce8a5f5f.389.123.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-1/validation/events.out.tfevents.1687229786.94c8ce8a5f5f.389.3.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-1/validation/events.out.tfevents.1687235702.94c8ce8a5f5f.389.147.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-1/events.out.tfevents.1687229786.94c8ce8a5f5f.389.0.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-1/events.out.tfevents.1687229786.94c8ce8a5f5f.389.1.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-1/events.out.tfevents.1687235098.94c8ce8a5f5f.389.120.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-24/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-24/events.out.tfevents.1687232393.94c8ce8a5f5f.389.92.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-24/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-24/train/events.out.tfevents.1687238453.94c8ce8a5f5f.389.238.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-24/train/events.out.tfevents.1687232393.94c8ce8a5f5f.389.94.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-24/events.out.tfevents.1687238453.94c8ce8a5f5f.389.237.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-24/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-24/validation/events.out.tfevents.1687232393.94c8ce8a5f5f.389.95.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-24/validation/events.out.tfevents.1687238453.94c8ce8a5f5f.389.239.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-24/events.out.tfevents.1687232393.94c8ce8a5f5f.389.93.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-24/events.out.tfevents.1687238453.94c8ce8a5f5f.389.236.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-29/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-29/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-29/train/events.out.tfevents.1687233121.94c8ce8a5f5f.389.114.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-29/train/events.out.tfevents.1687238859.94c8ce8a5f5f.389.258.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-29/events.out.tfevents.1687233121.94c8ce8a5f5f.389.112.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-29/events.out.tfevents.1687233121.94c8ce8a5f5f.389.113.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-29/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-29/validation/events.out.tfevents.1687238859.94c8ce8a5f5f.389.259.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-29/validation/events.out.tfevents.1687233122.94c8ce8a5f5f.389.115.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-29/events.out.tfevents.1687238859.94c8ce8a5f5f.389.256.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-29/events.out.tfevents.1687238859.94c8ce8a5f5f.389.257.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-8/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-8/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-8/train/events.out.tfevents.1687236388.94c8ce8a5f5f.389.174.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-8/train/events.out.tfevents.1687230459.94c8ce8a5f5f.389.30.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-8/events.out.tfevents.1687230459.94c8ce8a5f5f.389.28.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-8/events.out.tfevents.1687236388.94c8ce8a5f5f.389.172.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-8/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-8/validation/events.out.tfevents.1687230460.94c8ce8a5f5f.389.31.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-8/validation/events.out.tfevents.1687236389.94c8ce8a5f5f.389.175.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-8/events.out.tfevents.1687230459.94c8ce8a5f5f.389.29.v2 (deflated 18%)\n",
            "  adding: logs/hparam_tuning/run-8/events.out.tfevents.1687236388.94c8ce8a5f5f.389.173.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-12/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-12/events.out.tfevents.1687237036.94c8ce8a5f5f.389.189.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-12/events.out.tfevents.1687231144.94c8ce8a5f5f.389.45.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-12/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-12/train/events.out.tfevents.1687237036.94c8ce8a5f5f.389.190.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-12/train/events.out.tfevents.1687231144.94c8ce8a5f5f.389.46.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-12/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-12/validation/events.out.tfevents.1687231144.94c8ce8a5f5f.389.47.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-12/validation/events.out.tfevents.1687237037.94c8ce8a5f5f.389.191.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-12/events.out.tfevents.1687231144.94c8ce8a5f5f.389.44.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-12/events.out.tfevents.1687237036.94c8ce8a5f5f.389.188.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-26/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-26/events.out.tfevents.1687238618.94c8ce8a5f5f.389.244.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-26/events.out.tfevents.1687232535.94c8ce8a5f5f.389.101.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-26/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-26/train/events.out.tfevents.1687232535.94c8ce8a5f5f.389.102.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-26/train/events.out.tfevents.1687238618.94c8ce8a5f5f.389.246.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-26/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-26/validation/events.out.tfevents.1687232535.94c8ce8a5f5f.389.103.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-26/validation/events.out.tfevents.1687238619.94c8ce8a5f5f.389.247.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-26/events.out.tfevents.1687232535.94c8ce8a5f5f.389.100.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-26/events.out.tfevents.1687238618.94c8ce8a5f5f.389.245.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-20/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-20/events.out.tfevents.1687238068.94c8ce8a5f5f.389.221.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-20/events.out.tfevents.1687232012.94c8ce8a5f5f.389.76.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-20/events.out.tfevents.1687238068.94c8ce8a5f5f.389.220.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-20/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-20/train/events.out.tfevents.1687238068.94c8ce8a5f5f.389.222.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-20/train/events.out.tfevents.1687232012.94c8ce8a5f5f.389.78.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-20/events.out.tfevents.1687232012.94c8ce8a5f5f.389.77.v2 (deflated 20%)\n",
            "  adding: logs/hparam_tuning/run-20/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-20/validation/events.out.tfevents.1687232013.94c8ce8a5f5f.389.79.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-20/validation/events.out.tfevents.1687238069.94c8ce8a5f5f.389.223.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-30/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-30/events.out.tfevents.1687233323.94c8ce8a5f5f.389.116.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-30/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-30/train/events.out.tfevents.1687239061.94c8ce8a5f5f.389.262.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-30/train/events.out.tfevents.1687233323.94c8ce8a5f5f.389.118.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-30/events.out.tfevents.1687233323.94c8ce8a5f5f.389.117.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-30/events.out.tfevents.1687239061.94c8ce8a5f5f.389.261.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-30/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-30/validation/events.out.tfevents.1687233324.94c8ce8a5f5f.389.119.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-30/validation/events.out.tfevents.1687239062.94c8ce8a5f5f.389.263.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-30/events.out.tfevents.1687239061.94c8ce8a5f5f.389.260.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-25/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-25/events.out.tfevents.1687232464.94c8ce8a5f5f.389.96.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-25/events.out.tfevents.1687238535.94c8ce8a5f5f.389.241.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-25/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-25/train/events.out.tfevents.1687238535.94c8ce8a5f5f.389.242.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-25/train/events.out.tfevents.1687232464.94c8ce8a5f5f.389.98.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-25/events.out.tfevents.1687232464.94c8ce8a5f5f.389.97.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-25/events.out.tfevents.1687238535.94c8ce8a5f5f.389.240.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-25/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-25/validation/events.out.tfevents.1687232465.94c8ce8a5f5f.389.99.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-25/validation/events.out.tfevents.1687238536.94c8ce8a5f5f.389.243.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-16/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-16/train/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-16/train/events.out.tfevents.1687231439.94c8ce8a5f5f.389.62.v2 (deflated 78%)\n",
            "  adding: logs/hparam_tuning/run-16/train/events.out.tfevents.1687237347.94c8ce8a5f5f.389.206.v2 (deflated 79%)\n",
            "  adding: logs/hparam_tuning/run-16/events.out.tfevents.1687237347.94c8ce8a5f5f.389.205.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-16/events.out.tfevents.1687231439.94c8ce8a5f5f.389.61.v2 (deflated 19%)\n",
            "  adding: logs/hparam_tuning/run-16/validation/ (stored 0%)\n",
            "  adding: logs/hparam_tuning/run-16/validation/events.out.tfevents.1687237347.94c8ce8a5f5f.389.207.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-16/validation/events.out.tfevents.1687231440.94c8ce8a5f5f.389.63.v2 (deflated 81%)\n",
            "  adding: logs/hparam_tuning/run-16/events.out.tfevents.1687237347.94c8ce8a5f5f.389.204.v2 (deflated 23%)\n",
            "  adding: logs/hparam_tuning/run-16/events.out.tfevents.1687231439.94c8ce8a5f5f.389.60.v2 (deflated 23%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('logs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JIq6zrccZzKW",
        "outputId": "d43fbd28-40e1-4cd2-ac09-5b61729282f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bbf92b18-ec28-4efe-8a10-5882560faf62\", \"logs.zip\", 3164504)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi_hYwj3qjCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71fa2b5-a7d6-44bb-a2d0-04abf55ab493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "#we use the optimal model to make predictions:\n",
        "model=Sequential([Dense(units=16, activation='relu'), Dense(units=1)])\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.21))\n",
        "model.fit(X_scaled_train, y_train, epochs=1000, verbose=False)\n",
        "predictions_4= model.predict(X_scaled_test)[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "eyYNtDBRfi0K",
        "outputId": "493d8f46-36f0-45f5-8b01-d8c582fad809"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plot the prediction along with the ground truth as follows:\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(data_test.index, y_test, c='k')\n",
        "plt.plot(data_test.index,predictions_4,c='b')\n",
        "plt.plot(data_test.index,predictions_4,c='r')\n",
        "plt.plot(data_test.index,predictions_4,c='g')\n",
        "plt.xticks(range(0,252,10), rotation=60)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close price')\n",
        "plt.legend(['Truth', 'Neural network prediction'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naewF0vEi62V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}